{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello\n"
     ]
    }
   ],
   "source": [
    "print(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "aws_profile_name = \"dev\"\n",
    "aws_region = \"us-east-1\"\n",
    "import boto3\n",
    "from langchain_aws import ChatBedrockConverse\n",
    "\n",
    "boto3.setup_default_session(profile_name=aws_profile_name)\n",
    "BEDROCK_CLIENT = boto3.client(\"bedrock-runtime\", aws_region)\n",
    "llm = ChatBedrockConverse(\n",
    "    client=BEDROCK_CLIENT,\n",
    "    model=\"anthropic.claude-3-5-sonnet-20240620-v1:0\",\n",
    "    max_tokens=1000,\n",
    "    temperature=0.2,\n",
    "    top_p=0.9,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[StructuredTool(name='add', description='Add two numbers', args_schema={'properties': {'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}, 'required': ['a', 'b'], 'title': 'addArguments', 'type': 'object'}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x7ff00ad3bba0>), StructuredTool(name='multiply', description='Multiply two numbers', args_schema={'properties': {'a': {'title': 'A', 'type': 'integer'}, 'b': {'title': 'B', 'type': 'integer'}}, 'required': ['a', 'b'], 'title': 'multiplyArguments', 'type': 'object'}, response_format='content_and_artifact', coroutine=<function convert_mcp_tool_to_langchain_tool.<locals>.call_tool at 0x7ff00ad3b7e0>)]\n"
     ]
    }
   ],
   "source": [
    "from langchain_mcp_adapters.client import MultiServerMCPClient,SSEConnection\n",
    "\n",
    "async with MultiServerMCPClient(\n",
    "    {\n",
    "        \"math\": {\n",
    "            \"transport\": \"sse\",\n",
    "            \"timeout\": 1.0,\n",
    "            \"sse_read_timeout\": 1.0,\n",
    "            \"url\": \"http://localhost:8000/sse\",\n",
    "            \"headers\": None,\n",
    "            \"session_kwargs\": None\n",
    "        }\n",
    "    }\n",
    ") as client:\n",
    "    print(client.get_tools())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_mcp_adapters.client import MultiServerMCPClient,SSEConnection\n",
    "\n",
    "client = MultiServerMCPClient(\n",
    "    {\n",
    "        \"math\": {\n",
    "            \"transport\": \"sse\",\n",
    "            \"timeout\": 1.0,\n",
    "            \"sse_read_timeout\": 1.0,\n",
    "            \"url\": \"http://localhost:8000/sse\",\n",
    "            \"headers\": None,\n",
    "            \"session_kwargs\": None\n",
    "        }\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "object MultiServerMCPClient can't be used in 'await' expression",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[21]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m((\u001b[38;5;28;01mawait\u001b[39;00m client).get_tools())\n",
      "\u001b[31mTypeError\u001b[39m: object MultiServerMCPClient can't be used in 'await' expression"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langgraph.graph import MessagesState, StateGraph\n",
    "from langgraph.prebuilt import ToolNode\n",
    "\n",
    "\n",
    "def call_model(state: MessagesState):\n",
    "    print(\"Calling Model\")\n",
    "    print(state)\n",
    "    prompt = ChatPromptTemplate.from_messages(\n",
    "        [\n",
    "            (\n",
    "                \"system\",\n",
    "                \"\"\"\n",
    "                    Use tools when needed instead of asking permission.\n",
    "                    Don't reference the tool use in your response content.\n",
    "                \"\"\".strip(),\n",
    "            ),\n",
    "            *state[\"messages\"],\n",
    "        ]\n",
    "    )\n",
    "    chain = prompt | llm.bind_tools(client.get_tools())\n",
    "    response = chain.invoke({})\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "tool_node = ToolNode(client.get_tools())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import cast\n",
    "\n",
    "from langchain_core.messages import AIMessage\n",
    "from langgraph.graph import END, MessagesState\n",
    "\n",
    "\n",
    "def should_call_tool_or_end(state: MessagesState):\n",
    "    last_message = cast(AIMessage, state[\"messages\"][-1])\n",
    "    if last_message.tool_calls:\n",
    "        print(f\"Calling tool(s): {json.dumps(last_message.tool_calls, indent=2)}\")\n",
    "        return tool_node.name\n",
    "    return END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        +-----------+         \n",
      "        | __start__ |         \n",
      "        +-----------+         \n",
      "              *               \n",
      "              *               \n",
      "              *               \n",
      "       +------------+         \n",
      "       | call_model |         \n",
      "       +------------+         \n",
      "         .         .          \n",
      "       ..           ..        \n",
      "      .               .       \n",
      "+-------+         +---------+ \n",
      "| tools |         | __end__ | \n",
      "+-------+         +---------+ \n"
     ]
    }
   ],
   "source": [
    "graph = StateGraph(MessagesState)\n",
    "\n",
    "# definitions\n",
    "graph.add_node(call_model)\n",
    "graph.add_node(tool_node)\n",
    "\n",
    "# navigation\n",
    "graph.set_entry_point(call_model.__name__)\n",
    "graph.add_conditional_edges(\n",
    "    call_model.__name__,\n",
    "    should_call_tool_or_end,\n",
    ")\n",
    "graph.add_edge(tool_node.name, call_model.__name__)\n",
    "\n",
    "agent = graph.compile()\n",
    "agent.get_graph().print_ascii()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling Model\n",
      "{'messages': [HumanMessage(content=\"what's (3 + 5) x 12?\", additional_kwargs={}, response_metadata={}, id='1022870b-8b10-40ed-a641-cdfd2b57bd91')]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content=\"what's (3 + 5) x 12?\", additional_kwargs={}, response_metadata={}, id='1022870b-8b10-40ed-a641-cdfd2b57bd91'),\n",
       "  AIMessage(content=\"To calculate (3 + 5) x 12:\\n\\nFirst, let's solve what's inside the parentheses:\\n3 + 5 = 8\\n\\nNow we can multiply that result by 12:\\n8 x 12 = 96\\n\\nTherefore, the final answer is 96.\", additional_kwargs={}, response_metadata={'ResponseMetadata': {'RequestId': 'b8d83680-8a11-4a16-aedf-e485aa4e5ecc', 'HTTPStatusCode': 200, 'HTTPHeaders': {'date': 'Sun, 20 Apr 2025 23:10:32 GMT', 'content-type': 'application/json', 'content-length': '366', 'connection': 'keep-alive', 'x-amzn-requestid': 'b8d83680-8a11-4a16-aedf-e485aa4e5ecc'}, 'RetryAttempts': 0}, 'stopReason': 'end_turn', 'metrics': {'latencyMs': [1449]}, 'model_name': 'anthropic.claude-3-5-sonnet-20240620-v1:0'}, id='run-5cadecf7-8b27-4925-9629-cdfdfbf9b907-0', usage_metadata={'input_tokens': 43, 'output_tokens': 71, 'total_tokens': 114, 'input_token_details': {'cache_creation': 0, 'cache_read': 0}})]}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await agent.ainvoke({\"messages\": \"what's (3 + 5) x 12?\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
